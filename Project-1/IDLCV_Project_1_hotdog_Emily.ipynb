{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mS4PMkaHBGfQ"
   },
   "source": [
    "## Exercise 1.4 Hotdog -- no hotdog\n",
    "This is the poster hand-in project for the course. Please see the associated PDF for instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRIhx7PugJy3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35PhqXpWUZ7I"
   },
   "source": [
    "We always check that we are running on a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ic_gOv_pUZeB",
    "outputId": "7163f281-dd9c-448a-c317-88f7a72a576f"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAj64PJYgJzC"
   },
   "source": [
    "We provide you with a class that can load the *hotdog/not hotdog* dataset you should use from /dtu/datasets1/02516/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skzhd-QqBX5w",
    "outputId": "286281c0-2173-4051-8465-dbb89cd918d3"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "DATA_ROOT = \"/content/drive/MyDrive/hotdog_nothotdog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mUlnOuzgJzF"
   },
   "outputs": [],
   "source": [
    "class Hotdog_NotHotdog(torch.utils.data.Dataset):\n",
    "    def __init__(self, train, transform, data_path=DATA_ROOT):\n",
    "        'Initialization'\n",
    "        self.transform = transform\n",
    "        data_path = os.path.join(data_path, 'train' if train else 'test')\n",
    "        image_classes = [os.path.split(d)[1] for d in glob.glob(data_path +'/*') if os.path.isdir(d)]\n",
    "        image_classes.sort()\n",
    "        self.name_to_label = {c: id for id, c in enumerate(image_classes)}\n",
    "        self.image_paths = glob.glob(data_path + '/*/*.jpg')\n",
    "\n",
    "    def __len__(self):\n",
    "        'Returns the total number of samples'\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        'Generates one sample of data'\n",
    "        image_path = self.image_paths[idx]\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        c = os.path.split(os.path.split(image_path)[0])[1]\n",
    "        y = self.name_to_label[c]\n",
    "        X = self.transform(image)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JewkmhKlgJzN"
   },
   "source": [
    "Below is the simple way of converting the images to something that can be fed through a network.\n",
    "Feel free to use something other than $128\\times128$ images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZcilkL3dgJzP"
   },
   "outputs": [],
   "source": [
    "size = 128\n",
    "train_transform = transforms.Compose([transforms.Resize((size, size)),\n",
    "                                    transforms.ToTensor()])\n",
    "test_transform = transforms.Compose([transforms.Resize((size, size)),\n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "batch_size = 64\n",
    "trainset = Hotdog_NotHotdog(train=True, transform=train_transform)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "testset = Hotdog_NotHotdog(train=False, transform=test_transform)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ho-YRb6HgJzZ"
   },
   "source": [
    "Let's look at some images from our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "Sm4Ara7dgJza",
    "outputId": "d8a90035-eabc-472d-9714-382baeb6843b"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for i in range(21):\n",
    "    plt.subplot(5,7,i+1)\n",
    "    plt.imshow(np.swapaxes(np.swapaxes(images[i].numpy(), 0, 2), 0, 1))\n",
    "    plt.title(['hotdog', 'not hotdog'][labels[i].item()])\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12N0EYYsQPhJ"
   },
   "source": [
    "Now create a model and train it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AuxX7GAnQHQ6"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.convolutional = nn.Sequential(\n",
    "        nn.Conv2d(in_channels= 3, out_channels=32, kernel_size=3, padding=1),nn.BatchNorm2d(32),nn.ReLU(),\n",
    "        nn.Conv2d(in_channels= 32, out_channels=64, kernel_size=3, padding=1),nn.BatchNorm2d(64),nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(in_channels= 64, out_channels=128, kernel_size=3, padding=1),nn.BatchNorm2d(128), nn.ReLU(),\n",
    "        nn.Conv2d(in_channels= 128, out_channels=128, kernel_size=3, padding=1),nn.BatchNorm2d(128),nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fully_connected = nn.Sequential(\n",
    "          nn.Linear(128*64*64, 500),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(500, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutional(x)\n",
    "        #reshape x so it becomes flat, except for the first dimension (which is the minibatch)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fully_connected(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8IrqZyrcPdmG",
    "outputId": "a04da54f-265c-4fd0-d91e-db742cc76f1c"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import alexnet,vgg13_bn, vgg19_bn,  inception_v3, resnet50, resnet152, densenet161, densenet201, efficientnet_b4, efficientnet_b6\n",
    "\n",
    "models = []\n",
    "model = alexnet(weights=None)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)\n",
    "models.append(model)\n",
    "\n",
    "model = vgg13_bn(weights=None)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)\n",
    "models.append(model)\n",
    "\n",
    "model = vgg19_bn(weights=None)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)\n",
    "models.append(model)\n",
    "\n",
    "#model = inception_v3(weights=None, aux_logits=False)\n",
    "#model.fc = torch.nn.Linear(model.fc.in_features, 2)\n",
    "#models.append(model)\n",
    "\n",
    "model = resnet50(weights=None)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 2)\n",
    "models.append(model)\n",
    "\n",
    "model = resnet152(weights=None)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 2)\n",
    "models.append(model)\n",
    "\n",
    "model = densenet161(weights=None)\n",
    "model.classifier = torch.nn.Linear(model.classifier.in_features, 2)\n",
    "models.append(model)\n",
    "\n",
    "model = densenet201(weights=None)\n",
    "model.classifier = torch.nn.Linear(model.classifier.in_features, 2)\n",
    "models.append(model)\n",
    "\n",
    "model = efficientnet_b4(weights=None)\n",
    "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 2)\n",
    "models.append(model)\n",
    "model = efficientnet_b6(weights=None)\n",
    "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 2)\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NDfYBfYPkDK"
   },
   "outputs": [],
   "source": [
    "#We define the training as a function so we can easily re-use it.\n",
    "def train(model, optimizer, num_epochs=10):\n",
    "    loss_fun = nn.CrossEntropyLoss()\n",
    "    out_dict = {'train_acc': [],\n",
    "              'test_acc': [],\n",
    "              'train_loss': [],\n",
    "              'test_loss': []}\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), unit='epoch'):\n",
    "        model.train()\n",
    "        #For each epoch\n",
    "        train_correct = 0\n",
    "        train_loss = []\n",
    "        for minibatch_no, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            #Zero the gradients computed for each weight\n",
    "            optimizer.zero_grad()\n",
    "            #Forward pass your image through the network\n",
    "            output = model(data)\n",
    "            #Compute the loss\n",
    "            loss = loss_fun(output, target)\n",
    "            #Backward pass through the network\n",
    "            loss.backward()\n",
    "            #Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            #Compute how many were correctly classified\n",
    "            predicted = output.argmax(1)\n",
    "            train_correct += (target==predicted).sum().cpu().item()\n",
    "        #Comput the test accuracy\n",
    "        test_loss = []\n",
    "        test_correct = 0\n",
    "        model.eval()\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "            test_loss.append(loss_fun(output, target).cpu().item())\n",
    "            predicted = output.argmax(1)\n",
    "            test_correct += (target==predicted).sum().cpu().item()\n",
    "        out_dict['train_acc'].append(train_correct/len(trainset))\n",
    "        out_dict['test_acc'].append(test_correct/len(testset))\n",
    "        out_dict['train_loss'].append(np.mean(train_loss))\n",
    "        out_dict['test_loss'].append(np.mean(test_loss))\n",
    "        print(f\"Loss train: {np.mean(train_loss):.3f}\\t test: {np.mean(test_loss):.3f}\\t\",\n",
    "              f\"Accuracy train: {out_dict['train_acc'][-1]*100:.1f}%\\t test: {out_dict['test_acc'][-1]*100:.1f}%\")\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857,
     "referenced_widgets": [
      "fad5a567e7ef4e2289146b2dbd7330df",
      "802ebef0cddb4ece85acfebea18cd361",
      "bfc1cf3d0c394128b1271c494f81e8d6",
      "9b2f044485c645f9bd64df2e06b87389",
      "2d54e0a80a2d4313bc31c48250d29332",
      "a31d0c3d66994ca5a85f61e990638f0b",
      "921b66f2ecc743e394790e0332976b43",
      "ae0271ad2ac8467fbc4bd75d1434da09",
      "9cd525ab72b74232954d9ad51ad11447",
      "37790f320ba642078b9e4a28fdfd9d08",
      "d9255df12f064f3285fd88eea6136f76",
      "10b1d2d0b4834c65a881cb61f547301a",
      "8047f598c1fa4928b3bdf1826c6efa12",
      "77801e9dedfd450bb5379120fcfada42",
      "acd79679bc554953bfc778594ab0b991",
      "3e9cb3a3419043fa9bc27df24e97e6fc",
      "26bc7dfdd7b14823ac434d4aebbee4da",
      "97ec9c95bbe245f1a2dc90849eb33c97",
      "e2967655dce74e239fd3e4b9342f9818",
      "187e8080145c492a9b32cbf145104d2a",
      "d770758edb804ac9b5283d26a7112140",
      "1dd9e19b1f5e4151a62218ba39f4b24d",
      "2bdecfd346c049209744a8868a6794fe",
      "d3d5898565af4e9e9b1fa79f4426adf8",
      "5562c63016f5496191aa1795aa82bb87",
      "635ce7695815429fb71192e0f1999290",
      "7a20b560db2c4c888100bbdb50b4eb94",
      "5f0b58327c2d489387d9c3e915d85012",
      "cd9ffbd144f749b88e3d003a3284cb26",
      "cc4638453e8b4f2db5b1109476b1c8c0",
      "d77d405407d847949314695c8d564cb9",
      "bc93363f7dcf4a319882fe982c68a9a2",
      "9af4dc276aa84950ad2a0ca88059a903",
      "404849c6bc7e4545b869413f23e859dc",
      "cb8496782b004f3fa977aa649cc0feab",
      "3a7e446aaf0447959b82a81a04952485",
      "a7ee10515a9241779cc4665d6684def6",
      "4aa5ad95457c49b3a88c230f6d8074de",
      "84f8b35f4c8e4f04abbb6df927ad010a",
      "ba3992d13b494e24aaf4e12c543d8403",
      "ed050a3c0e464fc0af58545b3f801539",
      "1a9d18895da84d73ab89f306efe67319",
      "6d300cc52c714d14b8a287c7fad68ba2",
      "ed732864689e4fbdb74fab5256205446",
      "a9e3444c5f944709ba97235dc60b5791",
      "e586bd0c3d48438eb06025c7ecffd702",
      "5618118c88e548a7a7747d0bf051ecf5",
      "4f497039fa3c4788b1749308701f2fc3",
      "793bc962e0624dc1b1c70903424577f2",
      "58f470f1a9a443fc819feac90cd135f8",
      "da8d23fc73f04262a130f70ba66ab24c",
      "37f6f824565c49669e60636b888ab9f7",
      "a9516bbe38e44ecea7b5acfdb1676dc2",
      "e4a3e2aececf4b8cb966253be433e192",
      "5ca14ca92ab843a3bc6945fc7d270a20",
      "8b173a4759294813994aa59650dd1a93",
      "3a4db8ae86ff47128c5ecab632492603",
      "ec20de2d5d794be1b9b3b540d215e92b",
      "a33723fd3b6d40cf877ff3462c15fe39",
      "b3089883b2724595a2901d78eefb24e4",
      "63cdbaa63b6440ab8db45be9f5d926f2",
      "5eda4d1e5f064e02a58338cad09b2bba",
      "b52216f18fc344d9aee13f493f4ff9e1",
      "dd2265328cf6456898eee1976667a51e",
      "c3295e4ccbf84799aa478e85246f71e8",
      "b0efb4aaf59f40f1a410651042922b3a",
      "077ec80f5a3c4647bcc18915a0d0e0f3",
      "4981723569a04da091f3bd92dbf71f55",
      "6f13121ddb274311806764920448f208",
      "d2ae962db1a44b8e97bd48e71057824c",
      "fcf936a366c1480a9ca156f108e2b980",
      "bc24b9d5f1824db499512acf6659dea9",
      "b2c97a1c16e5411bbd85830ff631adbe",
      "35749d6d8ef844e280617ca791a97981",
      "3b71cf21f576451f924972f2f11730d1",
      "740dc893fa514ca5aa7784174cb90f00",
      "592d8a4e86ac4d4caa498d8f76f9c438",
      "149809688095442d9e0d0d2fe94b347e",
      "37e840bfd56f432e82c3858657b38d6d",
      "51322e27ebed465bbdd2900885ef499f",
      "d1133a27278b406db6cde020f83c59eb",
      "c592e6e5a96c48c1845471188c888767",
      "473041b0be134ea68145af69a673cc61",
      "fd062c24b52a4662964d6ef1172c7953",
      "b21f7133806446f0a26e0da0011fae0c",
      "1728dee9bc4441479a612ae68a4b7aac",
      "8bcbdae239694fed8bf2dd8ccf297566",
      "ed9ef85c12df407eb96f3ecc13b1b98c",
      "70d56cc57c924d8f80cca053a6255085",
      "9c39532b58554e8fae0304b931cb8a59",
      "6f1d2f954470486cb1de6e8a142fce4c",
      "f83e6c763be241388a1197d239aa7034",
      "f26e962fd83f4b5892b999fc13c147fd",
      "01383303fd894cfcb9ea12814885c0c4",
      "de6890fbf3e24ca792d3afd2edcd7c4b",
      "a843ef2754ce418aa6b0ee73d8a406f4",
      "9b32b15438bc4b8bb2aba4fee01a5472",
      "ffc6ddbf946e4eb989c6b357d8574777",
      "e443acccdfa1477d8e6e562d455dd0e6",
      "ccb9991dc6c2439e9b362538775e0569",
      "31407960137a4a89b0f2f2a4ed0fb0bb",
      "9a6c4c28177347b9b80f643c3a8298c8",
      "ac36bec0c076465dbd878b6358b597ba",
      "42458434d1a84ed9ab423d0183efc6ec",
      "ff2d7a053e2944a3bf556649a0ad081d",
      "fdcb2034d14044c08b8b285dc7c22aaf",
      "ebe86e3455064a43b2842aaba3037c0e",
      "81c858f47f1d4b53867af4448d5d09af",
      "0bee67fd7e8b4d5b8e47a3b7d32c1fd6",
      "ba8f82972ef04786a546f9a039827f01"
     ]
    },
    "id": "Dce25V3YPv9K",
    "outputId": "134e5369-3833-4369-80f1-fae27805ba1b"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for model in models:\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "  model.to(device)\n",
    "  results.append(train(model, optimizer, num_epochs=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fs0ddKwtkHOC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcU5C34Df3Lt"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptp8ku_ymA8Q"
   },
   "source": [
    "##Putting the results together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dvv0YsYqcegh",
    "outputId": "d6d7e75a-3993-4320-b6e9-5ddd53e37b15"
   },
   "outputs": [],
   "source": [
    "for result in results:\n",
    "  print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dAqgz44_nkZG",
    "outputId": "a6aa3f31-55b9-4960-f288-43b45e2b346f"
   },
   "outputs": [],
   "source": [
    "import re, ast\n",
    "\n",
    "raw = \"\"\"\n",
    "{'Name': \"AlexNet\", 'train_acc': [0.48851978505129456, 0.5227161700048852, 0.6057645334636053, 0.5657059110893992, 0.5696140693698095, 0.5930630190522717, 0.6844162188568637, 0.7171470444553004, 0.666829506595017, 0.7366878358573522, 0.7484123106985833, 0.7303370786516854, 0.7699071812408402, 0.7782120175867122, 0.7752808988764045], 'test_acc': [0.4806659505907626, 0.4806659505907626, 0.5220193340494093, 0.5612244897959183, 0.48603651987110635, 0.6288936627282492, 0.69656283566058, 0.625671321160043, 0.6987110633727175, 0.6928034371643395, 0.7175080558539205, 0.7373791621911923, 0.7389903329752954, 0.7051557465091299, 0.7271750805585392], 'train_loss': [np.float64(0.7311436254531145), np.float64(0.6902681011706591), np.float64(0.6586124934256077), np.float64(0.6874098479747772), np.float64(0.6907763779163361), np.float64(0.6712230760604143), np.float64(0.6041705943644047), np.float64(0.5805131327360868), np.float64(0.6270800642669201), np.float64(0.5611955095082521), np.float64(0.5288595631718636), np.float64(0.537388788536191), np.float64(0.4815087718889117), np.float64(0.48922291677445173), np.float64(0.4820363614708185)], 'test_loss': [np.float64(0.693427437543869), np.float64(0.7632245858510335), np.float64(0.689445988337199), np.float64(0.6798622936010361), np.float64(0.6863258401552836), np.float64(0.6461927205324173), np.float64(0.6262171864509583), np.float64(0.6419249812761942), np.float64(0.5924896627664566), np.float64(0.5717833191156387), np.float64(0.5692736799518268), np.float64(0.5518382082382838), np.float64(0.5770233829816183), np.float64(0.6017282247543335), np.float64(0.540881576637427)]}\n",
    "{'Name': \"vgg13_bn\",'train_acc': [0.5080605764533463, 0.5026868588177821, 0.5095261358085003, 0.5227161700048852, 0.5236932095749878, 0.5222276502198339, 0.5319980459208598, 0.525647288715193, 0.5764533463605276, 0.6580361504640938, 0.6712261846604788, 0.7034684904738642, 0.7318026380068393, 0.7557401074743527, 0.7542745481191988], 'test_acc': [0.4806659505907626, 0.495703544575725, 0.5075187969924813, 0.5112781954887218, 0.4833512352309345, 0.5042964554242749, 0.4849624060150376, 0.5048335123523093, 0.658968850698174, 0.6766917293233082, 0.6852846401718582, 0.5886143931256713, 0.7126745435016112, 0.6245972073039742, 0.6326530612244898], 'train_loss': [np.float64(9.275063119828701), np.float64(0.7325098551809788), np.float64(0.7426791395992041), np.float64(0.7096197139471769), np.float64(0.6987210232764482), np.float64(0.7035584021359682), np.float64(0.721199743449688), np.float64(0.7206432353705168), np.float64(0.7042439915239811), np.float64(0.6594348475337029), np.float64(0.6363064888864756), np.float64(0.5991468830034137), np.float64(0.5562013685703278), np.float64(0.5408083843067288), np.float64(0.5456254938617349)], 'test_loss': [np.float64(0.7191999812920888), np.float64(0.6977099816004435), np.float64(0.6915186266104381), np.float64(0.7008524219195048), np.float64(0.7035880585511526), np.float64(0.6922954976558685), np.float64(0.7197472850481669), np.float64(0.6964404741923015), np.float64(0.634106860558192), np.float64(0.627224846680959), np.float64(0.5958239446083705), np.float64(0.6838977724313736), np.float64(0.6846572920680046), np.float64(0.8207024815181891), np.float64(0.6784193535645803)]}\n",
    "{'Name': \"vgg19_bn\",'train_acc': [0.4880312652662433, 0.5188080117244749, 0.5266243282852956, 0.5227161700048852, 0.5183194919394235, 0.5393258426966292, 0.524181729360039, 0.5163654127992183, 0.5828041035661944, 0.655105031753786, 0.680019540791402, 0.6756228627259404, 0.7142159257449927, 0.7283829995114802, 0.7435271128480704], 'test_acc': [0.4806659505907626, 0.48442534908700324, 0.5010741138560687, 0.4806659505907626, 0.48442534908700324, 0.4940923737916219, 0.49624060150375937, 0.5703544575725027, 0.6611170784103115, 0.6697099892588615, 0.6723952738990333, 0.6750805585392051, 0.7352309344790547, 0.7459720730397422, 0.6992481203007519], 'train_loss': [np.float64(7.592355726286769), np.float64(0.8645626474171877), np.float64(0.8085560500621796), np.float64(0.7122009359300137), np.float64(0.7160707451403141), np.float64(0.695672644302249), np.float64(0.703281007707119), np.float64(0.7142615262418985), np.float64(0.6922761704772711), np.float64(0.6422864254564047), np.float64(0.6392371617257595), np.float64(0.6241326862946153), np.float64(0.602043435908854), np.float64(0.572532813064754), np.float64(0.542303261347115)], 'test_loss': [np.float64(0.7731438299020131), np.float64(0.9456956764062245), np.float64(0.7048340896765392), np.float64(0.7540398081143697), np.float64(0.7188283642133076), np.float64(0.6994657079378764), np.float64(0.7448499063650768), np.float64(0.6933883428573608), np.float64(0.6383684267600377), np.float64(0.6444981336593628), np.float64(0.6402479509512583), np.float64(0.6115933497746785), np.float64(0.5538618663946787), np.float64(0.5733175923426946), np.float64(0.6171202778816223)]}\n",
    "{'Name': \"resnet50\",'train_acc': [0.6502198339032731, 0.7733268197361993, 0.8016609672691744, 0.8216902784562775, 0.8500244259892525, 0.8744504152418173, 0.8891060087933561, 0.9174401563263312, 0.9159745969711773, 0.940400586223742, 0.9223253541768441, 0.9345383488031265, 0.9672691744015632, 0.9848558866634098, 0.9775280898876404], 'test_acc': [0.5725026852846402, 0.7368421052631579, 0.664876476906552, 0.6654135338345865, 0.6858216970998926, 0.6970998925886144, 0.7089151450053706, 0.7529538131041891, 0.6095596133190118, 0.7631578947368421, 0.6165413533834586, 0.7223415682062299, 0.6557465091299678, 0.7755102040816326, 0.7234156820622986], 'train_loss': [np.float64(0.8022947963327169), np.float64(0.5010210173204541), np.float64(0.46349837351590395), np.float64(0.4800900937989354), np.float64(0.37619945453479886), np.float64(0.2993182288482785), np.float64(0.26588596659712493), np.float64(0.22761676157824695), np.float64(0.20206017000600696), np.float64(0.16002833296079189), np.float64(0.20019900263287127), np.float64(0.16304857830982655), np.float64(0.09582075936486945), np.float64(0.04710142547264695), np.float64(0.06697199752670713)], 'test_loss': [np.float64(0.8641610915462176), np.float64(0.5657484054565429), np.float64(0.829359358549118), np.float64(2.0608018204569816), np.float64(1.030112830052773), np.float64(0.8709536086767912), np.float64(0.7165819555521011), np.float64(0.775167233000199), np.float64(1.2758288010954857), np.float64(0.8393914302190145), np.float64(2.255528270204862), np.float64(0.8522201620042325), np.float64(1.553634622444709), np.float64(1.0272338750461738), np.float64(1.2623452400167783)]}\n",
    "{'Name': \"resnet152\",'train_acc': [0.5476306790425012, 0.6638983878847093, 0.7313141182217879, 0.7674645823155838, 0.7796775769418661, 0.8075232046897899, 0.8436736687835857, 0.8475818270639961, 0.8720078163165608, 0.8866634098680997, 0.8637029799706888, 0.9140205178309722, 0.8954567659990229, 0.8959452857840743, 0.852467024914509], 'test_acc': [0.4806659505907626, 0.6707841031149302, 0.6917293233082706, 0.7142857142857143, 0.6992481203007519, 0.7443609022556391, 0.7180451127819549, 0.715359828141783, 0.7406015037593985, 0.7105263157894737, 0.6455424274973147, 0.6455424274973147, 0.7389903329752954, 0.6568206229860365, 0.7518796992481203], 'train_loss': [np.float64(0.8917481396347284), np.float64(0.6576127912849188), np.float64(0.5936464183032513), np.float64(0.5824227901175618), np.float64(0.49903993774205446), np.float64(0.4341424060985446), np.float64(0.4126716433092952), np.float64(0.3795394590124488), np.float64(0.3081863480620086), np.float64(0.2830235934816301), np.float64(0.3417885024100542), np.float64(0.23912254453171045), np.float64(0.2660307502374053), np.float64(0.26087427418679), np.float64(0.3228150480426848)], 'test_loss': [np.float64(0.9155325735608737), np.float64(0.6238509863615036), np.float64(0.6637520144383112), np.float64(0.6962200204531351), np.float64(0.6199139535427094), np.float64(0.7062415108084679), np.float64(0.5970335920651754), np.float64(0.9432202994823455), np.float64(0.7076967179775238), np.float64(0.7056572000185649), np.float64(1.1305590726435184), np.float64(1.4054781725009282), np.float64(0.7015482261776924), np.float64(1.303498496611913), np.float64(0.6337112501263619)]}\n",
    "{'Name': \"densenet161\",'train_acc': [0.6980947728382999, 0.7782120175867122, 0.7855398143624817, 0.7982413287738154, 0.8089887640449438, 0.8412310698583293, 0.8348803126526624, 0.8466047874938935, 0.8695652173913043, 0.865657059110894, 0.8768930141670738, 0.8949682462139716, 0.8817782120175867, 0.8607718612603811, 0.9027845627747924], 'test_acc': [0.7261009667024705, 0.7185821697099892, 0.7894736842105263, 0.7459720730397422, 0.6106337271750806, 0.80343716433942, 0.7851772287862513, 0.8098818474758325, 0.7545649838882922, 0.8039742212674543, 0.80343716433942, 0.7964554242749732, 0.7336197636949516, 0.6568206229860365, 0.7755102040816326], 'train_loss': [np.float64(0.6521603967994452), np.float64(0.48971568048000336), np.float64(0.4870593184605241), np.float64(0.4395723473280668), np.float64(0.41128136310726404), np.float64(0.37125223269686103), np.float64(0.383782341144979), np.float64(0.358037818223238), np.float64(0.31468853587284684), np.float64(0.31262738117948174), np.float64(0.295667196623981), np.float64(0.2431092243641615), np.float64(0.2902801192831248), np.float64(0.30380334611982107), np.float64(0.23760703671723604)], 'test_loss': [np.float64(0.6552126427491506), np.float64(0.6442564912140369), np.float64(0.4814742142955462), np.float64(0.5574675550063452), np.float64(1.3158999145651857), np.float64(0.43199774871269864), np.float64(0.52318618260324), np.float64(0.4812350963552793), np.float64(0.6162867850313584), np.float64(0.6053062875755131), np.float64(0.5015260051315029), np.float64(0.5227539269874494), np.float64(0.5583530068397522), np.float64(0.966236910627534), np.float64(0.5648612912744284)]}\n",
    "{'Name': \"densenet201\",'train_acc': [0.6917440156326331, 0.7576941866145579, 0.8065461651196874, 0.8172936003908158, 0.8373229115779189, 0.8549096238397655, 0.8505129457743038, 0.8832437713727406, 0.8886174890083048, 0.8998534440644846, 0.8954567659990229, 0.9106008793356131, 0.9325842696629213, 0.9389350268685882, 0.9335613092330239], 'test_acc': [0.7019334049409237, 0.771750805585392, 0.7529538131041891, 0.7685284640171858, 0.7561761546723953, 0.7502685284640171, 0.7277121374865736, 0.8050483351235231, 0.7787325456498388, 0.7191192266380236, 0.7212674543501612, 0.7636949516648764, 0.6702470461868958, 0.7679914070891515, 0.7303974221267454], 'train_loss': [np.float64(0.6210701102390885), np.float64(0.5059903869405389), np.float64(0.4265580512583256), np.float64(0.40714538749307394), np.float64(0.36357207549735904), np.float64(0.3350968868471682), np.float64(0.3332854830659926), np.float64(0.2872513234615326), np.float64(0.27239401591941714), np.float64(0.24137070612050593), np.float64(0.25984076503664255), np.float64(0.21603362867608666), np.float64(0.17458399035967886), np.float64(0.16520273312926292), np.float64(0.16613733978010714)], 'test_loss': [np.float64(0.6674421042203903), np.float64(0.5900862336158752), np.float64(0.5668809498349826), np.float64(0.5892462437351544), np.float64(0.6563102799157302), np.float64(0.5528054232398669), np.float64(1.0543931992103657), np.float64(0.4867444510261218), np.float64(0.9952109071115652), np.float64(0.8039100801649813), np.float64(0.8527987310041983), np.float64(0.6885422425965468), np.float64(0.858864360054334), np.float64(0.7115586216251055), np.float64(0.9532750484844049)]}\n",
    "{'Name': \"efficientnet_b4\",'train_acc': [0.5207620908646801, 0.5881778212017587, 0.680019540791402, 0.7210552027357108, 0.7498778700537372, 0.7850512945774304, 0.7938446507083536, 0.8124084025403029, 0.8568637029799707, 0.873961895456766, 0.9003419638495359, 0.8871519296531509, 0.9164631167562286, 0.9086468001954079, 0.9228138739618954], 'test_acc': [0.5193340494092373, 0.4806659505907626, 0.700859291084855, 0.7024704618689581, 0.7363050483351236, 0.7481203007518797, 0.7647690655209453, 0.706766917293233, 0.7411385606874329, 0.7212674543501612, 0.709452201933405, 0.7551020408163265, 0.765843179377014, 0.742749731471536, 0.7438238453276047], 'train_loss': [np.float64(0.755814703181386), np.float64(0.7113934215158224), np.float64(0.6477153208106756), np.float64(0.609376884996891), np.float64(0.5686407992616296), np.float64(0.5108896093443036), np.float64(0.4671897664666176), np.float64(0.4307660423219204), np.float64(0.35411211010068655), np.float64(0.31432155054062605), np.float64(0.2762421639636159), np.float64(0.29022951889783144), np.float64(0.22571303299628198), np.float64(0.229594950331375), np.float64(0.1760801167692989)], 'test_loss': [np.float64(0.6915001014868418), np.float64(0.6924619853496552), np.float64(0.9081325928370158), np.float64(0.7798934360345204), np.float64(0.5909831623236338), np.float64(0.5619236558675766), np.float64(0.5825493017832438), np.float64(0.7018606637914976), np.float64(0.6510872587561607), np.float64(0.5941462313135465), np.float64(0.7175831303000451), np.float64(0.6284406299392382), np.float64(0.6772500585764647), np.float64(0.6582215974728266), np.float64(0.8927115460236867)]}\n",
    "{'Name': \"efficientnet_b6\",'train_acc': [0.4870542256961407, 0.504152418172936, 0.5153883732291158, 0.5153883732291158, 0.5246702491450904, 0.6389838788470933, 0.6941866145578895, 0.7493893502686859, 0.7484123106985833, 0.7699071812408402, 0.7850512945774304, 0.7967757694186615, 0.8128969223253542, 0.8236443575964827, 0.8343917928676111], 'test_acc': [0.4806659505907626, 0.4806659505907626, 0.4806659505907626, 0.4806659505907626, 0.4806659505907626, 0.4806659505907626, 0.4806659505907626, 0.4806659505907626, 0.4806659505907626, 0.4806659505907626, 0.4806659505907626, 0.4806659505907626, 0.4806659505907626, 0.4806659505907626, 0.4806659505907626], 'train_loss': [np.float64(0.8040340188890696), np.float64(0.7361610271036625), np.float64(0.7333491910248995), np.float64(0.7275457959622145), np.float64(0.6997002214193344), np.float64(0.6860842723399401), np.float64(0.6250279303640127), np.float64(0.5488341776654124), np.float64(0.5589242428541183), np.float64(0.5020446218550205), np.float64(0.4930853098630905), np.float64(0.4630394596606493), np.float64(0.4384520063176751), np.float64(0.4083829540759325), np.float64(0.39347720798105)], 'test_loss': [np.float64(0.7011350234349568), np.float64(0.6996670265992483), np.float64(0.695439463853836), np.float64(0.6998155395189921), np.float64(0.7053070207436879), np.float64(0.7035076042016347), np.float64(0.7052374521891276), np.float64(0.7066363215446472), np.float64(0.6979444901148478), np.float64(0.6992155651251475), np.float64(0.7028636932373047), np.float64(0.7109996596972148), np.float64(0.7074590007464091), np.float64(0.7139172613620758), np.float64(0.7068133254845937)]}\n",
    "\"\"\"\n",
    "import re, ast\n",
    "\n",
    "def parse_models(raw: str):\n",
    "    # 1) drop np.float64(...) wrappers â†’ just keep the inner number\n",
    "    cleaned = re.sub(r'np\\.float64\\(([^)]+)\\)', r'\\1', raw.strip())\n",
    "    # 2) stitch the separate dicts into a list literal\n",
    "    as_list_literal = '[' + re.sub(r'}\\s*{', '}, {', cleaned) + ']'\n",
    "    # 3) safely parse to Python objects\n",
    "    return ast.literal_eval(as_list_literal)\n",
    "\n",
    "models = parse_models(raw)\n",
    "\n",
    "# quick sanity checks\n",
    "print(type(models), len(models))\n",
    "print(models[0]['Name'], len(models[0]['train_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "TOdUIYu8vN83",
    "outputId": "7a00daa0-f55c-421d-be53-ecc799f591ae"
   },
   "outputs": [],
   "source": [
    "\n",
    "import re, ast, pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def parse_models(raw: str):\n",
    "    cleaned = re.sub(r'np\\.float64\\(([^)]+)\\)', r'\\1', raw.strip())\n",
    "    as_list_literal = '[' + re.sub(r'}\\s*{', '}, {', cleaned) + ']'\n",
    "    return ast.literal_eval(as_list_literal)\n",
    "\n",
    "models = parse_models(raw)\n",
    "\n",
    "# Test accuracy over epochs\n",
    "plt.figure(figsize=(10,6))\n",
    "for m in models:\n",
    "    y = np.array(m['test_acc'], dtype=float)\n",
    "    x = np.arange(1, len(y)+1)\n",
    "    plt.plot(x, y, marker='o', label=m['Name'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Test Accuracy over Epochs')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arfkJWcankQj"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSHIr7L0nj68"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lBPnfLBceGO"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7YDvmr7kLI6"
   },
   "source": [
    "##ADDING AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBVUNBiC77wP"
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "class AlbumentationsTransform:\n",
    "    def __init__(self, size=224, augment=True):\n",
    "        aug = []\n",
    "        if augment:\n",
    "            aug = [\n",
    "                A.Blur(blur_limit=10),\n",
    "                A.RandomBrightnessContrast(brightness_limit=[-0.2, 0.2], contrast_limit=[-0.2, 0.2]),\n",
    "                A.GaussNoise(std_range=[0.01, 0.1], mean_range=[0.01, 0.1]),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.Rotate(limit=[15,45]),\n",
    "            ]\n",
    "        # Use standard normalization for pretrained models (ImageNet)\n",
    "        self.transform = A.Compose(aug + [\n",
    "            A.SmallestMaxSize(max_size=size),\n",
    "            A.RandomCrop(width=size, height=size),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # <--- Key!\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        img = self.transform(image=img)['image']\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0766b9252bbc4adeab37deab277cc64c",
      "5e6c5734c088403d8b23709cf8fcc486",
      "f114dcd246c645978764eb983bbfcfab",
      "93674f9661714f339c5a764f18742c3c",
      "94c27f244da3439f807cbf12af1ab49d",
      "1bdd7a5e407044dfaf76742bb7696b18",
      "bb654112327a480d8e940512449769a8",
      "a76f2dad7c624474a8585c3332a6c323",
      "725307e48fd24fb4ad7aad4b9976c702",
      "49bb899b41c840b9a025ccf2008b7d81",
      "d577a655249845fe95621afc75d58c75",
      "7389ee5fc13049de8080c6c19834b7bb",
      "facf1fbce24c40639d76a22f079f6f14",
      "e666dafe0f674a6f840fbddded8c9c37",
      "05ed1bf761ca43c7a355cc9bbeaf4f8a",
      "d5dfb928f1f542758e181ca9c5588333",
      "0bc835eb49f14a1cb65e9826a2b7a0ec",
      "4ecd4fdf8cdd4a88972191ca1aea188d",
      "74d1668721074183bafe2b813ed97c1f",
      "4cf24e9f08e64fa8a29abd81904f4f1e",
      "8876a4f85bcc49828d67f6e775401c4e",
      "12f4dc1bac8546049cf03884b94b5952",
      "9116556144cd4179831b3bc616cd4e81",
      "d8187a1fd0774aeb9c8210b84da275c5",
      "0593350c641342d584c8f0929760098b",
      "e63d2779e3a045978bb6c51e388cbe58",
      "61ce0b01e92347c8aa80a3b03a9d36d4",
      "071fedd3864245e79e488048aa812059",
      "f1b0b9429b5e49399f52af36c261d6db",
      "85e03113049a46ddbad2c3ddb7d7a561",
      "59215fdf76be4c99bd0157feced0dbce",
      "fdf501fe1f084b67910f9fc495363fb0",
      "15cfbad796cb467cb3668a7256c12c46",
      "28c44e3142ee447185a394f5715ec4ed",
      "312b2ac431074f099c563caa735205e6",
      "db9fbb9e096543789d7a75d806c03eaa",
      "90656510d221440d8ad1b28a5d08d259",
      "2d0c53f0dc4a40c6a08df65bb8013ba7",
      "cb56e83e2c4d4cd7872cecb1ff95dd02",
      "5ad68c7a97d0407c8ebeae2ba21bb129",
      "bbfd6ac620b54474bb012435ddd243c9",
      "3ba7785244a0424f878c16cdd9e44ba1",
      "d45fd07e16304757aadf0486678d59a2",
      "c320891d2b934f71acc7cc5ba8710e74",
      "fc3690b08ec542f7be8ea734c6dad704",
      "cfeb2baebf0b4bde8980edc54462fc4a",
      "d351e3a3794a42b49c5adb779c4ac647",
      "eddeab3ae0804ac98b154870784de1e9",
      "4208186fd2094dbcbdf3cf3b2505b29a",
      "d4551ec60f42417684fc6da1b1654fd4",
      "30ec7a2099c445f38d314714ea526767",
      "2ec26e9f41a246f1ae957c9922b600b5",
      "9f7c0e2f05c84707ae16f03763a0aaf8",
      "9f34c5108dcb447bb8795de65026b53d",
      "12372d63dfc24edf9b7439ef432d66e4",
      "ef35da0625e046fda52698b6b2b64547",
      "5f55e4619c38454bab10ac41568dc310",
      "ae9c4db23db7453690668b68fe69a617",
      "278785cded3a41bc806664d74e3608f9",
      "7245e58033a74ee6acae7562943141da",
      "3955241b19944e2b9886cdb19dfc8dfd",
      "3f6e45cf0f584cb397f1cae8760a8d4d",
      "5a4d47de2b764bd5ae091549de832a00",
      "d08848d662ab42fb843e9ea2538f1284",
      "30955a87289f40c5ba82acca7d3e9849",
      "1b6c7d6aa0094fd38b1650c7b7577fc6",
      "724016eb268a4da4b4c6cb994672512b",
      "6cc0996e80784e28a131068202c5852b",
      "bf0346ccbeb745c99ac557de3b741b80",
      "63ed73847540467fbbae2c46ca03db3b",
      "9fa7754e1c7541b4a09071fd479bd9d7",
      "947dff105ef44508b74b4a79a457fcc7",
      "3841a257007449aa8dd4396f87598f79",
      "255c7c45a68b4cd5986f04943504ca70",
      "d7b919e47a46472491ff5d3d4c1a3311",
      "4abdd0274bbc42cda353a4db03993c73",
      "603850a990d245fd8559d1e074798812",
      "2f31728c8ef148ffa6b73c5f36912185",
      "41324df7874b44259061644c000a78e7",
      "1f0935712db44ba6a608b126bb2378e8",
      "3a00bb022871450fb1331b9b7829fe33",
      "53e924287e2146dda1d366d536f6afbe",
      "e419e213b6e9494c80d65c08f0260715",
      "da0b7ae47baa47ee9db7ea74bf63598c",
      "b2712004dfc24db5a08aa21e503f6d6d",
      "5dd45a5ee7334578949807cba24d8911",
      "a1bb6f78dd6340e48f5ac60e146e8984",
      "30ecb146c2d34bc9b8bac8480f892245",
      "7ddc946a6821434ba664399efdebdcd1",
      "a02a4099497b426aa18bd2f93d1c8bdd",
      "e667763ba60744d0a0c34f32ad9e3fbd",
      "360a894710ba4daa9a61d6a5479a3eec",
      "7f38a2b6ad934528aed01d4197c82c28",
      "8fb8bf507e87409a9965e7239aa25583",
      "3840f5277a5b415f93fdba6437b79618",
      "e20d4504fbef43339ac5d5e951b44513",
      "01c714cd33cb466ea33356de82dc32e4",
      "5a096cc5b8f9415ea2d5e8f79b548607",
      "54bcc1d0bf05407596fe6f15f0ce6947",
      "506103a495a84eb68c27f23c39a1834a",
      "66511a0429d544f49e557b4ebbec1507",
      "7a0454d3df594d41ab4802aeabaf16b8",
      "1b25e094cd964353bc31f98e407728ff",
      "8c5ca9daa0544ec3a79f6a8d3869c07a",
      "98df8e2b01e840c99606828dc791426b",
      "2386605fdf6043e09de114b67455630e",
      "fdcebd0160ab40ff9070a91b24e88b11",
      "6262cf0767e448879e2e6cc8a8525ebe",
      "91ee2f3927ff42faae850f39ab1c2f95",
      "dd6db1c57dd044b8971824f8bc8e43b5",
      "996cf1b8af924e74a171b92ef72bdd28",
      "90d2724839494611ad20392329db2b5e",
      "89655abad74341889f707671bdc9e7db",
      "1a2a7112f9c14c7bbe25d3ba88a2cbb5",
      "75e666383e1b4ddeaa5c8afd07260c2a",
      "593c90f6e1094ba19ce7b5cce50b4a52",
      "abd839c50d7945de810bf1e6b010fbd7",
      "9e42acc5857b4cf59e2899515f464406",
      "130f2df2fd0a41c59d65964920c24e69",
      "a97f938371674a5caf172140c44841f0",
      "0dddff6a29ac4e83b869533838edd2f4",
      "90a6df0404ed46549d17ebdeb883e91d",
      "a6f32806b0454732a52fe5fd3d95e228",
      "effba5bcb5b44e2ba016b9e5d6ffe6bd",
      "9e759060b2e346f9a37b9974c16bba9f",
      "b67677ca261f43a89a1f5dbb7fe89acb",
      "643447f5b4f3433287be7928ff92d3ad",
      "2647afd4d98245a2bd7eec13fbf59e34",
      "febd3036003f448cb3c180769b5cda8b",
      "6728f23cd17744268be6c05e0b3df909",
      "7cc8a5d32dc548cf8a177383f8d8b153",
      "3db2783bd0b34568aa0947dd1f7e6a4e",
      "bb3f2dcaa577408b958ae3ba1e58c9e4",
      "41198d8317494d438bfb7890739f5e2d",
      "16ec222ea00e4778912038a186a07ad9",
      "0e3bc9d07b58456abf0afea0f35f33a7",
      "bdce3c5d56434c43a59399c267493b80",
      "40b5be6940ec48b3a8fe8d9121dd7bde",
      "0530475979624d5da71e1ef70df4b6dc",
      "ddee16c9f4a0431dbde503dc546fe019",
      "7d4f134381054df3a6b1a08e9a72318d",
      "0d12212dce5c40f89d38c89bf4a3897c",
      "a005d164e2d449069e6da43b39f91719",
      "22e90bdca899448f97ab3cd78fe6a40b",
      "27b4719161724e60b543306279141b1e",
      "14d62219099942b6a973c4a3ae067113",
      "c3789a5e86fb4bffbdc8ce7e5a7625aa",
      "2135554a97df4aea86df56a03e7f8401",
      "8b521ee2aa1c46abbf4eaf9a2af096d8",
      "00d8e02f6e2749278078b8f486566746",
      "81e1655041084571babe4db9bf0818f8",
      "7ad0490e2bee47b68dd51aacdc05e810",
      "fa1cd37821b84e5391d6fe0ac44cea1e",
      "01fa7933ee024d31b50a76fc96c49c9c",
      "3442166d55c543ccb532643c39dc8759",
      "51731d734f6d4da5a9d46baa067c140c",
      "2018ae406b1b46a591b9c52509b0310f",
      "c41345802e084932b2b2fffc954bf16d",
      "cc02ba5bef0447a69ea4f7409b603fa6",
      "f81ee275eef24baa86009f1efc7d6fde",
      "5f61a4a4c77e41cf88043387375504c2",
      "c0297b93e296445e82c1ec0033670c9d",
      "dcc7b5c633e64605a709328a6199d697",
      "9d92a54380a94020ae8d3b70d868018d",
      "56209846b2b24e74a42b4109fb4d9545",
      "57bf7d24d77d410ab23a05414c40399d",
      "5271f3fc304048fa836e766b00dc0432",
      "6f4f554a4a7546e2b255a01ad8858230",
      "22ff010e3a12486dae419c0bdf9a2a28",
      "a72bf0dd1d224fc5a566a4444dce4f4e",
      "1743f84871b04e6fb484e6862f8df3c3",
      "13631a9bfd3a44cb848407fcb52977c3",
      "fec302a6bdf94937ad6838bebf9748bf",
      "385ff932bc664948bc603a2456259b0e",
      "4ae513670d4d4a13bc9ffe756fd98b2c",
      "a7203589e72748b09c15a3a06be40cba"
     ]
    },
    "id": "BVUsP0Re5tD4",
    "outputId": "066762af-2b00-4e14-a080-b08f066555c7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.models import alexnet,vgg13_bn, vgg19_bn,  inception_v3, resnet50, resnet152, densenet161, densenet201, efficientnet_b4, efficientnet_b6\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "DATA_ROOT = \"/content/drive/MyDrive/hotdog_nothotdog\"\n",
    "\n",
    "class Hotdog_NotHotdog(torch.utils.data.Dataset):\n",
    "    def __init__(self, train, transform, data_path=DATA_ROOT):\n",
    "        'Initialization'\n",
    "        self.transform = transform\n",
    "        data_path = os.path.join(data_path, 'train' if train else 'test')\n",
    "        image_classes = [os.path.split(d)[1] for d in glob.glob(data_path +'/*') if os.path.isdir(d)]\n",
    "        image_classes.sort()\n",
    "        self.name_to_label = {c: id for id, c in enumerate(image_classes)}\n",
    "        self.image_paths = glob.glob(data_path + '/*/*.jpg')\n",
    "\n",
    "    def __len__(self):\n",
    "        'Returns the total number of samples'\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        'Generates one sample of data'\n",
    "        image_path = self.image_paths[idx]\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        c = os.path.split(os.path.split(image_path)[0])[1]\n",
    "        y = self.name_to_label[c]\n",
    "        X = self.transform(image)\n",
    "        return X, y\n",
    "\n",
    "size = 224\n",
    "train_transform = AlbumentationsTransform(size=size, augment=True)\n",
    "test_transform = AlbumentationsTransform(size=size, augment=False)\n",
    "batch_size = 32\n",
    "trainset = Hotdog_NotHotdog(train=True, transform=train_transform)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "testset = Hotdog_NotHotdog(train=False, transform=test_transform)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)\n",
    "\n",
    "model = densenet161(weights=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model.classifier = torch.nn.Linear(model.classifier.in_features, 2)\n",
    "model.to(device)\n",
    "\n",
    "train(model, optimizer, num_epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6etcw0Tr6tUk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
