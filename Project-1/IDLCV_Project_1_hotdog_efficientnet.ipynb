{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeo76g15abaf"
   },
   "source": [
    "## Exercise 1.4 Hotdog -- no hotdog\n",
    "This is the poster hand-in project for the course. Please see the associated PDF for instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35PhqXpWUZ7I"
   },
   "source": [
    "We always check that we are running on a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAj64PJYgJzC"
   },
   "source": [
    "We provide you with a class that can load the *hotdog/not hotdog* dataset you should use from /dtu/datasets1/02516/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hotdog_NotHotdog(torch.utils.data.Dataset):\n",
    "    def __init__(self, train, transform, data_path='./hotdog_nothotdog/hotdog_nothotdog'):\n",
    "        'Initialization'\n",
    "        self.transform = transform\n",
    "        data_path = os.path.join(data_path, 'train' if train else 'test')\n",
    "        image_classes = [os.path.split(d)[1] for d in glob.glob(data_path +'/*') if os.path.isdir(d)]\n",
    "        image_classes.sort()\n",
    "        self.name_to_label = {c: id for id, c in enumerate(image_classes)}\n",
    "        self.image_paths = glob.glob(data_path + '/*/*.jpg')\n",
    "\n",
    "    def __len__(self):\n",
    "        'Returns the total number of samples'\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        'Generates one sample of data'\n",
    "        image_path = self.image_paths[idx]\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        c = os.path.split(os.path.split(image_path)[0])[1]\n",
    "        y = self.name_to_label[c]\n",
    "        X = self.transform(image)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JewkmhKlgJzN"
   },
   "source": [
    "Below is the simple way of converting the images to something that can be fed through a network.\n",
    "Feel free to use something other than $128\\times128$ images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 224\n",
    "#train_transform = transforms.Compose([transforms.Resize((size, size)),\n",
    "#                                    transforms.ToTensor()])\n",
    "#test_transform = transforms.Compose([transforms.Resize((size, size)),\n",
    "#                                    transforms.ToTensor()])\n",
    "\n",
    "#\"\"\" #optional data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((size, size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((size, size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "#\"\"\"\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "trainset = Hotdog_NotHotdog(train=True, transform=train_transform)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "testset = Hotdog_NotHotdog(train=False, transform=test_transform)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12N0EYYsQPhJ"
   },
   "source": [
    "Now create a model and train it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2047 pics of hotdogs & not hotdogs in train set\n",
    "#1862 pics of hotdog & not hotdogs in test set\n",
    "#-> balanced sets, no weight for sampler\n",
    "\n",
    "#EfficientNet B0 model\n",
    "model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=1)\n",
    "model = model.to(torch.device(\"cuda\"))\n",
    "\n",
    "#oprtimizer (might change)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-4, weight_decay=1e-4) #maybe more\n",
    "#loss function (might change -> nn.LogSoftmax or nn.CrossEntropyLoss or ?)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "#scheduler for adaptive learning rate, if the gradient is stuck\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logs accuracy&loss\n",
    "output_dict = {'training_loss': [], 'test_loss': [], 'accuracy': [], 'f1': []}\n",
    "\n",
    "#training loop\n",
    "epochs = 20\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "for epoch in tqdm(range(epochs), unit='epoch'):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for _, (data, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        #to device\n",
    "        data = data.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        #zero gradient\n",
    "        optimizer.zero_grad()\n",
    "        #forward pass\n",
    "        outputs = model(data)\n",
    "        #compute loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        #backward pass\n",
    "        loss.backward()\n",
    "        #update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        #add loss to plot\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_training_loss = train_loss / len(train_loader)\n",
    "\n",
    "    #model validation / test accuracy\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    predicted_val = []\n",
    "    true_val = []\n",
    "\n",
    "    #same with test set\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data = data.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            #squeeze btw 0 and 1\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            #add to list if predicted ie. if probs > 0.5\n",
    "            predicted_val.extend((probs > 0.5).astype(int))\n",
    "            true_val.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    accuracy = accuracy_score(true_val, predicted_val)\n",
    "    f1 = f1_score(true_val, predicted_val)\n",
    "\n",
    "    output_dict['training_loss'].append(avg_training_loss)\n",
    "    output_dict['test_loss'].append(avg_test_loss)\n",
    "    output_dict['accuracy'].append(accuracy)\n",
    "    output_dict['f1'].append(f1)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_training_loss:.4f} | Val Loss: {avg_test_loss:.4f} | Acc: {accuracy:.4f} | F1: {f1:.4f}\")\n",
    "    #upudating learning rate\n",
    "    scheduler.step(avg_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns\n",
    "\n",
    "#metrics and plots\n",
    "def plot_metrics(output_dict, true, preds):\n",
    "\n",
    "    #losses and accuracies\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(output_dict['training_loss'], label='Training Loss')\n",
    "    plt.plot(output_dict['test_loss'], label='Test Loss')\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss over Epochs\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    plt.plot(output_dict['accuracy'], label='Accuracy')\n",
    "    plt.plot(output_dict['f1'], label='F1-score')\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy & F1\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    #confusion matrix\n",
    "    cm = confusion_matrix(true, preds)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=[\"Not hotdog\", \"Hotdog\"], yticklabels=[\"Not hotdog\", \"Hotdog\"])\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted values\")\n",
    "    plt.ylabel(\"True values\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    #ROC curve & AUC\n",
    "    fpr, tpr, _ = roc_curve(true, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('FP rate')\n",
    "    plt.ylabel('TP rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "model.eval()\n",
    "preds = []\n",
    "true = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "        preds.extend((probs > 0.5).astype(int))\n",
    "        true.extend(labels.cpu().numpy())\n",
    "\n",
    "#call\n",
    "plot_metrics(output_dict, true_val, predicted_val)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
