{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cB-S4m1ZA8oC"
   },
   "source": [
    "# Exercise 1.3\n",
    "\n",
    "## Classification of CIFAR10 images\n",
    "### Optimizers\n",
    "In this exercise we will classify the images from the CIFAR10 dataset. We will use different optimizers and compare their convergence speed. First we import the libraries that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7z8ctltTA8oS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Dg7mIJnA8os"
   },
   "source": [
    "We always check that we are running on a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fLXvswP1A8os"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code will run on GPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9FYktcoA8pB"
   },
   "source": [
    "In this exercise we will classify images from the [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset. \n",
    "CIFAR10 has 60000 colour images of size 32x32 equally distributed in 10 classes.\n",
    "* You should load this dataset (hint: it is a built-in dataset in pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HR6Y_F1MA8pF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "mean: tensor([0.4914, 0.4822, 0.4465])\n",
      "std: tensor([0.2470, 0.2435, 0.2616])\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset_for_mean_std = datasets.CIFAR10(root=\"./data\", train=True, download=True,\n",
    "                            transform=transforms.ToTensor())\n",
    "\n",
    "train_loader_for_mean_std = torch.utils.data.DataLoader(trainset_for_mean_std, batch_size=50000, shuffle=False)\n",
    "\n",
    "data = next(iter(train_loader_for_mean_std))[0]  # shape [50000, 3, 32, 32]\n",
    "mean = data.mean(dim=[0,2,3])\n",
    "std  = data.std(dim=[0,2,3])\n",
    "\n",
    "print(\"mean:\", mean)\n",
    "print(\"std:\", std)\n",
    "\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "test_tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "trainset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_tf)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=test_tf)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7JBaV9XA8pU"
   },
   "source": [
    "* Make a CNN to train on the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HAUxC2nCA8pZ"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IZNf-XPFA8pu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary())\n",
    "model = Network()\n",
    "model.to(device)\n",
    "#Initialize the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CqWfe3U5A8qB"
   },
   "outputs": [],
   "source": [
    "#We define the training as a function so we can easily re-use it.\n",
    "def train(model, optimizer, num_epochs=10):\n",
    "    def loss_fun(output, target):\n",
    "        return F.nll_loss(torch.log(output), target)\n",
    "    out_dict = {'train_acc': [],\n",
    "              'test_acc': [],\n",
    "              'train_loss': [],\n",
    "              'test_loss': []}\n",
    "  \n",
    "    for epoch in tqdm(range(num_epochs), unit='epoch'):\n",
    "        model.train()\n",
    "        #For each epoch\n",
    "        train_correct = 0\n",
    "        train_loss = []\n",
    "        for minibatch_no, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            #Zero the gradients computed for each weight\n",
    "            optimizer.zero_grad()\n",
    "            #Forward pass your image through the network\n",
    "            output = model(data)\n",
    "            #Compute the loss\n",
    "            loss = loss_fun(output, target)\n",
    "            #Backward pass through the network\n",
    "            loss.backward()\n",
    "            #Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            #Compute how many were correctly classified\n",
    "            predicted = output.argmax(1)\n",
    "            train_correct += (target==predicted).sum().cpu().item()\n",
    "        #Comput the test accuracy\n",
    "        test_loss = []\n",
    "        test_correct = 0\n",
    "        model.eval()\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "            test_loss.append(loss_fun(output, target).cpu().item())\n",
    "            predicted = output.argmax(1)\n",
    "            test_correct += (target==predicted).sum().cpu().item()\n",
    "        out_dict['train_acc'].append(train_correct/len(trainset))\n",
    "        out_dict['test_acc'].append(test_correct/len(testset))\n",
    "        out_dict['train_loss'].append(np.mean(train_loss))\n",
    "        out_dict['test_loss'].append(np.mean(test_loss))\n",
    "        print(f\"Loss train: {np.mean(train_loss):.3f}\\t test: {np.mean(test_loss):.3f}\\t\",\n",
    "              f\"Accuracy train: {out_dict['train_acc'][-1]*100:.1f}%\\t test: {out_dict['test_acc'][-1]*100:.1f}%\")\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HB7NHbYfA8qf"
   },
   "source": [
    " * Train the network and plot make a plot of the loss and accuracy for both training and with the epoch on the x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "c053536qA8qk"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6355d029781c4dcdb696eb28c959d8a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31855a9917f640379f9cd098b83d3b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m out_dict = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(out_dict)\n\u001b[32m      3\u001b[39m plt.plot()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, optimizer, num_epochs)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m#Update the weights\u001b[39;00m\n\u001b[32m     26\u001b[39m optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m train_loss.append(\u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m#Compute how many were correctly classified\u001b[39;00m\n\u001b[32m     30\u001b[39m predicted = output.argmax(\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "out_dict = train(model, optimizer)\n",
    "print(out_dict)\n",
    "plt.plot()\n",
    "plt.legend(('Test error','Train eror'))\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmxbypURA8q2"
   },
   "source": [
    "* Discuss what you see. Are you overfitting to the training data? Do you not learn anything? What can you change to do better?\n",
    "\n",
    "* Repeat the above steps but using Adam as the optimizer. Use Pytorch's defaults parameters. Do you learn faster?\n",
    "* Which optimizer works best for you?\n",
    "* Plot the test and test errors for both SGD and Adam in one plot\n",
    "* Try adding Batch normalisation after your convolutional layers. Does it help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMMyz4WhA8q6"
   },
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQhB2BH3A8q8"
   },
   "source": [
    "Now you will create and train a ResNet.\n",
    "* Implement the Residual block as a network below using convolutional kernel size $3\\times3$ according to the figure below\n",
    "![Residual block](https://cdn-images-1.medium.com/max/800/1*D0F3UitQ2l5Q0Ak-tjEdJg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "g-FoRHmrA8rC"
   },
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.resBlock = nn.Sequential(\n",
    "            nn.Conv2d(n_features, n_features, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_features, n_features, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n_features),\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.resBlock(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZDp_0SgA8rS"
   },
   "source": [
    "The following code is a sanity of your residual block network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9YRnqMaTA8rW"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m C = \u001b[32m4\u001b[39m\n\u001b[32m      3\u001b[39m res_block = ResNetBlock(C)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(res_block.state_dict())==\u001b[32m4\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, weight \u001b[38;5;129;01min\u001b[39;00m res_block.state_dict().items():\n\u001b[32m      6\u001b[39m     weight*=\u001b[32m0\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#Sanity test of your implementation\n",
    "C = 4\n",
    "res_block = ResNetBlock(C)\n",
    "assert(len(res_block.state_dict())==4)\n",
    "for name, weight in res_block.state_dict().items():\n",
    "    weight*=0\n",
    "    desired_shape = {'bias': (C,), 'weight': (C, C, 3, 3)}[name.split('.')[-1]]\n",
    "    assert(desired_shape==weight.shape)\n",
    "x = torch.randn(32, C, 32,32)\n",
    "assert(torch.abs(res_block(x)-F.relu(x)).max()==0)\n",
    "print(\"Passed sanity check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKFu5rWDA8rv"
   },
   "source": [
    "We define a network that uses your `ResNetBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "waKiIu5NA8r2"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, n_in, n_features, num_res_blocks=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        #First conv layers needs to output the desired number of features.\n",
    "        conv_layers = [nn.Conv2d(n_in, n_features, kernel_size=3, stride=1, padding=1),\n",
    "                       nn.ReLU()]\n",
    "        for i in range(num_res_blocks):\n",
    "            conv_layers.append(ResNetBlock(n_features))\n",
    "        self.res_blocks = nn.Sequential(*conv_layers)\n",
    "        self.fc = nn.Sequential(nn.Linear(32*32*n_features, 2048),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(2048, 512),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(512,10),\n",
    "                                nn.Softmax(dim=1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.res_blocks(x)\n",
    "        #reshape x so it becomes flat, except for the first dimension (which is the minibatch)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QF1XvsLGA8sH"
   },
   "source": [
    "Let's train our new ResNet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "qWychvPvA8sN"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658f3b244f4d46449c56380726cc1cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f310bdfe0a408aa4447ce6bd099fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: nan\t test: nan\t Accuracy train: 10.0%\t test: 10.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38dec94bab664c399c5c1c3ca5dd73fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: nan\t test: nan\t Accuracy train: 10.0%\t test: 10.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2df53a373448f997f1a4aaafafd243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: nan\t test: nan\t Accuracy train: 10.0%\t test: 10.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fe6d353ba2418e990478f1babed610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: nan\t test: nan\t Accuracy train: 10.0%\t test: 10.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2471293b0124439dbd940b8a7785d446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: nan\t test: nan\t Accuracy train: 10.0%\t test: 10.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9cbfca1d204a0a88b3b6059d3f8e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: nan\t test: nan\t Accuracy train: 10.0%\t test: 10.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241c03ad9276472c9135663e7dc8c2b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: nan\t test: nan\t Accuracy train: 10.0%\t test: 10.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27bf2583cf4468580f2eba347474aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: nan\t test: nan\t Accuracy train: 10.0%\t test: 10.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b83362e06b646b0b2a9f1ebcdd9599b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: nan\t test: nan\t Accuracy train: 10.0%\t test: 10.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4523c1fcd024ddcaeb6e5592e4087a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#Initialize the optimizer\u001b[39;00m\n\u001b[32m      4\u001b[39m optimizer = torch.optim.SGD(model.parameters(), lr=\u001b[32m0.1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m out_dict = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, optimizer, num_epochs)\u001b[39m\n\u001b[32m     16\u001b[39m data, target = data.to(device), target.to(device)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m#Zero the gradients computed for each weight\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m#Forward pass your image through the network\u001b[39;00m\n\u001b[32m     20\u001b[39m output = model(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torch-ex/lib/python3.11/site-packages/torch/_compile.py:32\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     29\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     30\u001b[39m     fn.__dynamo_disable = disable_fn\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torch-ex/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    630\u001b[39m prior = _maybe_set_eval_frame(callback)\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    634\u001b[39m     _maybe_set_eval_frame(prior)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torch-ex/lib/python3.11/site-packages/torch/optim/optimizer.py:947\u001b[39m, in \u001b[36mOptimizer.zero_grad\u001b[39m\u001b[34m(self, set_to_none)\u001b[39m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    945\u001b[39m     per_device_and_dtype_grads = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_zero_grad_profile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_groups\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparams\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torch-ex/lib/python3.11/site-packages/torch/autograd/profiler.py:750\u001b[39m, in \u001b[36mrecord_function.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting():\n\u001b[32m    749\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch._C.DisableTorchFunctionSubclass():\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_record_function_exit\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_RecordFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    752\u001b[39m     torch.ops.profiler._record_function_exit(record)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torch-ex/lib/python3.11/site-packages/torch/_ops.py:940\u001b[39m, in \u001b[36mTorchBindOpOverload.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m940\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_must_dispatch_in_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# When any inputs are FakeScriptObject, we need to\u001b[39;00m\n\u001b[32m    942\u001b[39m         \u001b[38;5;66;03m# skip c++ dispatcher and dispatch in python through _get_dispatch of python_dispatcher\u001b[39;00m\n\u001b[32m    943\u001b[39m         \u001b[38;5;66;03m# because C++ dispatcher will check the schema and cannot recognize FakeScriptObject.\u001b[39;00m\n\u001b[32m    944\u001b[39m         \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    945\u001b[39m         \u001b[38;5;66;03m# Note:\u001b[39;00m\n\u001b[32m    946\u001b[39m         \u001b[38;5;66;03m# 1. We only register the torchbind op temporarily as effectful op because we only want\u001b[39;00m\n\u001b[32m    947\u001b[39m         \u001b[38;5;66;03m#    the effect token functionalization logic to be applied during tracing. Otherwise, the behavior\u001b[39;00m\n\u001b[32m    948\u001b[39m         \u001b[38;5;66;03m#    of the eagerly executing the op might change after tracing.\u001b[39;00m\n\u001b[32m    949\u001b[39m         \u001b[38;5;66;03m# 2. We don't want to register the op as effectful for all torchbind ops in ctor because this might\u001b[39;00m\n\u001b[32m    950\u001b[39m         \u001b[38;5;66;03m#    cause unexpected behavior for some autograd.profiler ops e.g. profiler._record_function_exit._RecordFunction.\u001b[39;00m\n\u001b[32m    951\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._register_as_effectful_op_temporarily():\n\u001b[32m    952\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dispatch_in_python(args, kwargs, \u001b[38;5;28mself\u001b[39m._fallthrough_keys())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torch-ex/lib/python3.11/site-packages/torch/_ops.py:994\u001b[39m, in \u001b[36m_must_dispatch_in_python\u001b[39m\u001b[34m(args, kwargs)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_must_dispatch_in_python\u001b[39m(args, kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m994\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpytree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtree_any\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    995\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    996\u001b[39m \u001b[43m            \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_library\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfake_class_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFakeScriptObject\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torch-ex/lib/python3.11/site-packages/torch/utils/_pytree.py:1203\u001b[39m, in \u001b[36mtree_any\u001b[39m\u001b[34m(pred, tree, is_leaf)\u001b[39m\n\u001b[32m   1197\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtree_any\u001b[39m(\n\u001b[32m   1198\u001b[39m     pred: Callable[[Any], \u001b[38;5;28mbool\u001b[39m],\n\u001b[32m   1199\u001b[39m     tree: PyTree,\n\u001b[32m   1200\u001b[39m     is_leaf: Optional[Callable[[PyTree], \u001b[38;5;28mbool\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1201\u001b[39m ) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m   1202\u001b[39m     flat_args = tree_iter(tree, is_leaf=is_leaf)\n\u001b[32m-> \u001b[39m\u001b[32m1203\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mmap\u001b[39m(pred, flat_args))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torch-ex/lib/python3.11/site-packages/torch/utils/_pytree.py:904\u001b[39m, in \u001b[36mtree_iter\u001b[39m\u001b[34m(tree, is_leaf)\u001b[39m\n\u001b[32m    902\u001b[39m \u001b[38;5;66;03m# Recursively flatten the children\u001b[39;00m\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m child_pytrees:\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m tree_iter(child, is_leaf=is_leaf)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torch-ex/lib/python3.11/site-packages/torch/utils/_pytree.py:904\u001b[39m, in \u001b[36mtree_iter\u001b[39m\u001b[34m(tree, is_leaf)\u001b[39m\n\u001b[32m    902\u001b[39m \u001b[38;5;66;03m# Recursively flatten the children\u001b[39;00m\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m child_pytrees:\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m tree_iter(child, is_leaf=is_leaf)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torch-ex/lib/python3.11/site-packages/torch/utils/_pytree.py:890\u001b[39m, in \u001b[36mtree_iter\u001b[39m\u001b[34m(tree, is_leaf)\u001b[39m\n\u001b[32m    883\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    884\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtree_unflatten(leaves, treespec): Expected `treespec` to be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    885\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minstance of TreeSpec but got item of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(treespec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    886\u001b[39m         )\n\u001b[32m    887\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m treespec.unflatten(leaves)\n\u001b[32m--> \u001b[39m\u001b[32m890\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtree_iter\u001b[39m(\n\u001b[32m    891\u001b[39m     tree: PyTree,\n\u001b[32m    892\u001b[39m     is_leaf: Optional[Callable[[PyTree], \u001b[38;5;28mbool\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    893\u001b[39m ) -> Iterable[Any]:\n\u001b[32m    894\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get an iterator over the leaves of a pytree.\"\"\"\u001b[39;00m\n\u001b[32m    895\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_leaf(tree, is_leaf=is_leaf):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = ResNet(3, 8)\n",
    "model.to(device)\n",
    "#Initialize the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "out_dict = train(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoLIRQCr23Es"
   },
   "source": [
    "\n",
    "\n",
    "Do you get nan loss at some point during training? \n",
    "This can be caused by the numerical instability of using softmax and log as two functions. \n",
    "* Change your network and loss to use a layer that combines the softmax log into one such as `nn.LogSoftmax`. You can also use `nn.CrossEntropyLoss` which also integrates `nn.NLLLoss`."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 1.3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch-ex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
